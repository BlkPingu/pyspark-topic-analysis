{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing some libraries\n",
    "from pyspark.context import SparkContext\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "books = []\n",
    "\n",
    "path = '../../data/texts/English/'\n",
    "\n",
    "for filepath in glob.glob(os.path.join(path, '*.txt')):\n",
    "    with open(os.path.join(os.getcwd(), filepath), 'r') as file:\n",
    "        data = file.read().replace('\\n', '')\n",
    "        filename = filepath.replace(path, \"\", 1)\n",
    "        name = filename.replace(\".txt\", \"\", 1)\n",
    "        books.append((name, data))\n",
    "\n",
    "df = pd.DataFrame(books, columns =[['Name','Text']])\n",
    "\n",
    "df.to_csv(\"en_books.csv\")"
   ]
  },
  {
   "source": [
    "# check if spark context is defined\n",
    "sc = SparkContext('local').getOrCreate()\n",
    "print(sc.version)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.1.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                Name  \\\n",
       "0              Captains Courageous - Rudyard Kipling   \n",
       "1                              Dracula - Bram Stoker   \n",
       "2  Three Men in a Boat (to Say Nothing of The Dog...   \n",
       "3                        Bush Boys, The - Mayne Reid   \n",
       "4                      Macbeth - William Shakespeare   \n",
       "\n",
       "                                                Text  \n",
       "0  Rudyard KiplingCAPTAINS COURAGEOUSCHAPTER IThe...  \n",
       "1  Bram StokerDraculaPrefaceHow these papers have...  \n",
       "2  Jerome K. JeromeTHREE MEN IN A BOAT(TO SAY NOT...  \n",
       "3  Captain Mayne ReidThe Bush BoysChapter One.The...  \n",
       "4  William ShakespeareMacbethAct I, Scene 1A dese...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Name</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Captains Courageous - Rudyard Kipling</td>\n      <td>Rudyard KiplingCAPTAINS COURAGEOUSCHAPTER IThe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dracula - Bram Stoker</td>\n      <td>Bram StokerDraculaPrefaceHow these papers have...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Three Men in a Boat (to Say Nothing of The Dog...</td>\n      <td>Jerome K. JeromeTHREE MEN IN A BOAT(TO SAY NOT...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bush Boys, The - Mayne Reid</td>\n      <td>Captain Mayne ReidThe Bush BoysChapter One.The...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Macbeth - William Shakespeare</td>\n      <td>William ShakespeareMacbethAct I, Scene 1A dese...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/Tobias/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "# stuff we'll need for text processing\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re as re\n",
    "from pyspark.ml.feature import CountVectorizer , IDF\n",
    "\n",
    "# stuff we'll need for building the model\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "\n",
    "# reading the data\n",
    "data = sqlContext.read.format(\"csv\") \\\n",
    "   .options(header='true', inferschema='true') \\\n",
    "   .load(os.path.realpath(\"en_books.csv\"))\n",
    "\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "reviews = data.rdd.map(lambda x : x['Text']).filter(lambda x: x is not None)\n",
    "StopWords = stopwords.words(\"english\")\n",
    "\n",
    "type(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = reviews                                                   \\\n",
    "    .map( lambda document: document.strip().lower())               \\\n",
    "    .map( lambda document: re.split(\" \", document))          \\\n",
    "    .map( lambda word: [x for x in word if x.isalpha()])           \\\n",
    "    .map( lambda word: [x for x in word if len(x) > 3] )           \\\n",
    "    .map( lambda word: [x for x in word if x not in StopWords])    \\\n",
    "    .zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txts = sqlContext.createDataFrame(tokens, [\"list_of_words\",'index'])\n",
    "# TF\n",
    "cv = CountVectorizer(inputCol=\"list_of_words\", outputCol=\"raw_features\", vocabSize=5000, minDF=10.0)\n",
    "cvmodel = cv.fit(df_txts)\n",
    "result_cv = cvmodel.transform(df_txts)\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(result_cv)\n",
    "result_tfidf = idfModel.transform(result_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                       list_of_words  index  \\\n",
       "0  [rudyard, kiplingcaptains, courageouschapter, ...      0   \n",
       "1  [stokerdraculaprefacehow, papers, placed, sequ...      1   \n",
       "2  [jerome, jeromethree, nothing, thoughts, idle,...      2   \n",
       "3  [captain, mayne, reidthe, bush, boyschapter, b...      3   \n",
       "4  [william, shakespearemacbethact, scene, desert...      4   \n",
       "\n",
       "                                        raw_features  \\\n",
       "0  (87.0, 418.0, 86.0, 11.0, 102.0, 25.0, 103.0, ...   \n",
       "1  (1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "2  (348.0, 279.0, 151.0, 93.0, 113.0, 56.0, 113.0...   \n",
       "3  (478.0, 44.0, 347.0, 426.0, 153.0, 48.0, 87.0,...   \n",
       "4  (37.0, 2.0, 12.0, 47.0, 5.0, 30.0, 32.0, 19.0,...   \n",
       "\n",
       "                                            features  \n",
       "0  (12.323594984483336, 68.39709914079329, 14.072...  \n",
       "1  (0.14165051706302684, 0.16362942378180212, 0.1...  \n",
       "2  (49.29437993793334, 45.65260923512279, 24.7080...  \n",
       "3  (67.70894715612683, 7.199694646399293, 56.7794...  \n",
       "4  (5.241069131331993, 0.32725884756360424, 1.963...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>list_of_words</th>\n      <th>index</th>\n      <th>raw_features</th>\n      <th>features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[rudyard, kiplingcaptains, courageouschapter, ...</td>\n      <td>0</td>\n      <td>(87.0, 418.0, 86.0, 11.0, 102.0, 25.0, 103.0, ...</td>\n      <td>(12.323594984483336, 68.39709914079329, 14.072...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[stokerdraculaprefacehow, papers, placed, sequ...</td>\n      <td>1</td>\n      <td>(1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>(0.14165051706302684, 0.16362942378180212, 0.1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[jerome, jeromethree, nothing, thoughts, idle,...</td>\n      <td>2</td>\n      <td>(348.0, 279.0, 151.0, 93.0, 113.0, 56.0, 113.0...</td>\n      <td>(49.29437993793334, 45.65260923512279, 24.7080...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[captain, mayne, reidthe, bush, boyschapter, b...</td>\n      <td>3</td>\n      <td>(478.0, 44.0, 347.0, 426.0, 153.0, 48.0, 87.0,...</td>\n      <td>(67.70894715612683, 7.199694646399293, 56.7794...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[william, shakespearemacbethact, scene, desert...</td>\n      <td>4</td>\n      <td>(37.0, 2.0, 12.0, 47.0, 5.0, 30.0, 32.0, 19.0,...</td>\n      <td>(5.241069131331993, 0.32725884756360424, 1.963...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "tfidf_df = result_tfidf.toPandas()\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.clustering import LDA\n",
    "result_df = result_tfidf['index','features'].toDF('index','features')\n",
    "lda_model = LDA().fit(result_df)\n",
    "wordNumbers = 10\n",
    "topicIndices = lda_model.describeTopics(maxTermsPerTopic = wordNumbers)\n",
    "vocab = cvmodel.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_render(topic):\n",
    "    terms = topic[1]\n",
    "    result = []\n",
    "    for i in range(wordNumbers):\n",
    "        term = vocab[terms[i]]\n",
    "        result.append(term)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topic0 : ['traversed', 'board', 'smallest', 'entitled', 'indignant', 'struggled', 'backs', 'breathe', 'professed', 'curtain']\nTopic1 : ['thou', 'thee', 'hath', 'hast', 'doth', 'holy', 'paris', 'villain', 'heaven', 'hence']\nTopic2 : ['funeral', 'event', 'break', 'want', 'science', 'faith', 'asking', 'nation', 'cable', 'tricks']\nTopic3 : ['holmes', 'said', 'upon', 'would', 'could', 'anyone', 'come', 'professor', 'nothing', 'baker']\nTopic4 : ['holmes', 'upon', 'wolf', 'said', 'captain', 'come', 'would', 'could', 'dollars', 'police']\nTopic5 : ['thou', 'thee', 'hast', 'hath', 'holmes', 'gods', 'self', 'eternal', 'thence', 'angels']\nTopic6 : ['holmes', 'said', 'upon', 'police', 'would', 'professor', 'could', 'peter', 'london', 'back']\nTopic7 : ['question', 'perfect', 'france', 'belonged', 'things', 'fully', 'selfish', 'smoking', 'fear', 'defend']\nTopic8 : ['said', 'would', 'could', 'miss', 'like', 'george', 'never', 'know', 'must', 'come']\nTopic9 : ['holmes', 'said', 'upon', 'would', 'police', 'could', 'anyone', 'professor', 'door', 'back']\n"
     ]
    }
   ],
   "source": [
    "topics_final = topicIndices.rdd.map(lambda topic: topic_render(topic)).collect()\n",
    "\n",
    "\n",
    "for topic in range(len(topics_final)):\n",
    "    print (\"Topic\" + str(topic) + \" : \" + str(topics_final[topic]))"
   ]
  }
 ]
}